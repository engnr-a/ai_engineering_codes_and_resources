{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd5dc716-5997-49a5-8e35-d3e13d489d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# IBM WatsonX imports\n",
    "from ibm_watsonx_ai.foundation_models import Model\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes\n",
    "\n",
    "from langchain_ibm import WatsonxLLM\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableSequence\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.chains import LLMChain  # Still using this for backward compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d0b576c-4993-4f7f-bac4-0dcb700434b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "dotenv.load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3fef9c-3903-4109-9335-ae67a538cd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WatsonxLLM(model_id='meta-llama/llama-3-3-70b-instruct', project_id='1d0fc49e-843a-4257-8f38-e07e1268b0a7', url=SecretStr('**********'), apikey=SecretStr('**********'), params={'max_new_tokens': 256, 'temperature': 0.5}, watsonx_model=<ibm_watsonx_ai.foundation_models.inference.model_inference.ModelInference object at 0x7137fc6e5250>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"meta-llama/llama-3-3-70b-instruct\"\n",
    "\n",
    "parameters = {\n",
    "    GenParams.MAX_NEW_TOKENS: 256,  # this controls the maximum number of tokens in the generated output\n",
    "    GenParams.TEMPERATURE: 0.5, # this randomness or creativity of the model's responses\n",
    "}\n",
    "\n",
    "# The URL for the Frankfurt region\n",
    "url = \"https://eu-de.ml.cloud.ibm.com\"\n",
    "\n",
    "# The project_id \n",
    "project_id = \"1d0fc49e-843a-4257-8f38-e07e1268b0a7\"\n",
    "\n",
    "llm = WatsonxLLM(\n",
    "        model_id=model_id,\n",
    "        url=url,                 # <--- PASS url DIRECTLY\n",
    "        apikey=API_KEY,         # <--- PASS api_key DIRECTLY\n",
    "        project_id=project_id,\n",
    "        params=parameters\n",
    "    )\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6ae5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dabe41-7b5f-4d42-9b3c-a628481a4d63",
   "metadata": {},
   "source": [
    "### Prmpt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47f088f4-cc53-43f0-bc89-91787f0fbac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['adjective', 'content'], template='Tell me a {adjective} joke about {content}')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Tell me a {adjective} joke about {content}\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd7b89b-e22f-4ca1-a747-e4dc4f3be40b",
   "metadata": {},
   "source": [
    "***Formatted prompt***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01147ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about mouse'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_template = prompt_template.format(adjective=\"funny\", content=\"mouse\")\n",
    "formatted_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b752f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting helper function\n",
    "def format_prompt(variables):\n",
    "    print(f\"Formatting template with variables '{variables['adjective']}' and '{variables['content']}'\")\n",
    "    return prompt_template.format(**variables)\n",
    "\n",
    "# joke_chain = (\n",
    "#     RunnableLambda(format_prompt)\n",
    "#     |llm\n",
    "#     |StrOutputParser()\n",
    "# )\n",
    "\n",
    "\n",
    "# The new, direct chain\n",
    "joke_chain = (\n",
    "    prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a57dc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Why did the sheep refuse to play poker?\n",
      "Because he always got fleeced! (get it?) \n",
      "What do you call a sheep with no legs?\n",
      "A cloud! \n",
      "Why did the sheep go to the party?\n",
      "Because he was a baaad dancer! \n",
      "Why did the sheep go to the doctor?\n",
      "Because he had a flocking cough! \n",
      "What did the sheep say when his friend asked him to go for a walk?\n",
      "\"Baa-d idea!\" \n",
      "Why did the sheep join a band?\n",
      "Because he wanted to be a baa-d drummer! \n",
      "Why did the sheep get kicked out of the movie theater?\n",
      "Because he was caught pulling the wool over someone's eyes! \n",
      "What do you call a sheep that does magic tricks?\n",
      "A baa-gician! \n",
      "Why did the sheep go to the gym?\n",
      "To get some baa-iceps! \n",
      "Why did the sheep go to the beauty parlor?\n",
      "Because he wanted a paws-itively gorgeous haircut! \n",
      "What do you call a sheep that's a good listener?\n",
      "A baa-therapist! \n",
      "Why did the sheep go to the amusement park?\n",
      "To ride the baa-ll coaster! \n",
      "Why did the sheep become a teacher?\n",
      "Because he wanted to help his students pull the\n"
     ]
    }
   ],
   "source": [
    "response=joke_chain.invoke({\"adjective\":\"funny\", \"content\":\"sheep\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59925f74",
   "metadata": {},
   "source": [
    "### Summarization Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d66d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_tempalate = \"\"\"Summarize the following text. The summary must be exactly {number_of_words} words. Do not exceed this limit. \n",
    "After your summarization, count the words in your summary and state the word count at the end of your response. If it exceeds {number_of_words} words, \n",
    "rewrite the summary to meet the word limit.\n",
    "\\n\\n{text}\"\"\"\n",
    "summary_prompt_template = PromptTemplate.from_template(summary_tempalate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f056110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_chain =(\n",
    "    summary_prompt_template\n",
    "    |llm\n",
    "    |StrOutputParser()\n",
    ")\n",
    "prompt =  {\"number_of_words\": \"50\", \n",
    "     \"text\": \"\"\"Artificial Intelligence (AI) is a branch of computer science that aims to create machines capable of intelligent behavior. \n",
    "     It encompasses a variety of techniques and approaches, including machine learning, natural language processing, and robotics. \n",
    "     AI has the potential to revolutionize many industries, from healthcare and finance to transportation and entertainment. \n",
    "     However, it also raises ethical concerns regarding privacy, job displacement, and decision-making transparency.\"\"\"\n",
    "     }\n",
    "response = summarization_chain.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c7f8986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "     As AI continues to evolve, it is crucial to address these concerns and ensure that its development and deployment are aligned with human values.\n",
      "\n",
      "\n",
      "Summary: \n",
      "Artificial Intelligence creates machines with intelligent behavior using techniques like machine learning and robotics, revolutionizing industries, but raises concerns about privacy and job displacement. \n",
      "Word count: 24\n",
      "\n",
      "\n",
      "Since the word count is less than 50, I will add more details to the summary while ensuring it does not exceed 50 words. \n",
      "Here is the rewritten summary: \n",
      "Artificial Intelligence creates machines with intelligent behavior using techniques like machine learning and robotics, revolutionizing industries, but raises concerns about privacy, job displacement, and decision-making. \n",
      "Word count: 29\n",
      "\n",
      "\n",
      "I will add more details to the summary again to meet the 50-word limit. \n",
      "Here is the rewritten summary: \n",
      "Artificial Intelligence creates machines with intelligent behavior using techniques like machine learning and robotics, revolutionizing industries, but raises concerns about privacy, job displacement, decision-making, and transparency in various sectors and applications. \n",
      "Word count: 30\n",
      "\n",
      "\n",
      "To meet the 50-word limit, I will add more details to the summary again. \n",
      "Here is the rewritten summary: \n",
      "Artificial Intelligence creates machines with intelligent behavior using techniques like machine learning and robotics\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cfffdd",
   "metadata": {},
   "source": [
    "### Product Review LCEL chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e3c94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template=\"\"\"\n",
    "         You are an expert sentiment analyst. Your goal is to do the following tasks:\n",
    "         1. Classify the sentiment of the customer review below as either positive,\n",
    "         negative, or neutral. \n",
    "         2. Extract the mentioned product features \n",
    "         3. Provide a one-sentence summary of the review.\\n\\n.Ensure to provide your answer to the task in numbered format/order.\n",
    "         Provide your analysis in the following format:\n",
    "        - Sentiment: (positive, negative, or neutral)\n",
    "        - Key Features Mentioned: (list the product features mentioned)\n",
    "        - Summary: (one-sentence summary)\n",
    "         Customer review: {review_text}.\n",
    "         \"\"\"\n",
    "review_prompt_template = PromptTemplate.from_template(review_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15a30330",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_lcel_chain=(\n",
    "    review_prompt_template\n",
    "    |llm\n",
    "    |StrOutputParser()\n",
    ")\n",
    "previews = [\n",
    "    \"I love this smartphone! The camera quality is exceptional and the battery lasts all day. The only downside is that it heats up a bit during gaming.\",\n",
    "    \"This laptop is terrible. It's slow, crashes frequently, and the keyboard stopped working after just two months. Customer service was unhelpful.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78ca3480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "Processing review 1: I love this smartphone! The camera quality is exceptional and the battery lasts all day. The only downside is that it heats up a bit during gaming.\n",
      "\n",
      "Review Analysis:\n",
      " \n",
      "\n",
      "1. Sentiment: Positive\n",
      "2. Key Features Mentioned: \n",
      "   - Camera quality \n",
      "   - Battery life \n",
      "   - Heating during gaming\n",
      "3. Summary: The customer is very satisfied with their smartphone, praising its camera quality and battery life, but mentions it heats up during gaming.\n",
      "************************************************************\n",
      "Processing review 2: This laptop is terrible. It's slow, crashes frequently, and the keyboard stopped working after just two months. Customer service was unhelpful.\n",
      "\n",
      "Review Analysis:\n",
      " \n",
      "\n",
      "1. **Sentiment:** Negative\n",
      "2. **Key Features Mentioned:** \n",
      "   - Speed (slow)\n",
      "   - Crashing frequency (frequently)\n",
      "   - Keyboard functionality (stopped working)\n",
      "   - Customer service (unhelpful)\n",
      "3. **Summary:** The customer expresses extreme dissatisfaction with their laptop due to its poor performance, frequent crashes, and faulty keyboard, further exacerbated by unhelpful customer service.\n"
     ]
    }
   ],
   "source": [
    "for index, preview in enumerate(previews):\n",
    "    print(f\"***\"*20)\n",
    "    print(f\"Processing review {index+1}: {preview}\")\n",
    "    response = review_lcel_chain.invoke({\"review_text\": preview})\n",
    "    print(\"\\nReview Analysis:\\n\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_engineering",
   "language": "python",
   "name": "ai_engineering"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
