[project]
name = "ai_engineering"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "jupyterlab>=4.4.9",
    "python-dotenv>=1.1.1",
    "ibm-watsonx-ai==1.1.2",
    "langchain==0.2.11",
    "langchain-ibm==0.1.7",
    "langchain-core==0.2.43",
    "langchain-community==0.2.10",
    "langchain-experimental==0.0.62",
    "langchainhub==0.1.18",
    "pypdf==4.2.0",
    "chromadb==1.0.12",
    "tenacity==8.2.3",
    "ipykernel>=6.30.1",
    "ibm-watson-machine-learning==1.0.367",
    "gradio==4.44.1",
    "transformers>=4.57.0",
    "torch>=2.8.0", # this idio is gonna bring all NVIDIA CUDA libraries and consume space...using below instead or try +cpu
    #"torch==2.8.0+cpu",
    "llama-index==0.11.8",
    "llama-index-core==0.11.8",
    "llama-index-llms-ibm==0.2.0",
    "llama-index-embeddings-ibm==0.2.0",
    "llama-index-readers-web==0.2.2",
    "requests==2.32.2",
    "pydantic==2.10.6",
    "llama-index-vector-stores-chroma>=0.2.2",
    "llama-index-embeddings-langchain>=0.2.1",
    "llama-index-llms-langchain>=0.4.2",
]
